{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Word in a sentence prediction Using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go to the process of reading a text file and come up with input and output for a RNN network, next day we will see how to use the model to predict the next word in the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using [this tutorial](https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I step : Load the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(path):\n",
    "    \"\"\"\n",
    "    load the document at the given path\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as file:\n",
    "        text = file.read()\n",
    "        return text      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿BOOK I.\n",
      "\n",
      "I went down yesterday to the Piraeus with Glaucon the son of Ariston,\n",
      "that I might offer up my prayers to the goddess (Bendis, the Thracian\n",
      "Artemis.); and also because I wanted to see in what\n"
     ]
    }
   ],
   "source": [
    "doc = load_document('./data/republic_clean.txt')\n",
    "print(doc[:201])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Step clean the text : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the text is the most important part of any NLP task, is to clean the text, it envolves spliting the text into sentence and sentences into tokens,removing puncuactions and stop word., NLTK library is good at this but let use raw pyhton and string method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a translation table to remove punctuaction from each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_document(doc):\n",
    "    \"\"\"\n",
    "    Clean the document pass in parameter.\n",
    "    \"\"\"\n",
    "    doc = doc.replace('--', ' ')\n",
    "    tokens = doc.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus', 'with', 'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i', 'might', 'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess', 'bendis', 'the', 'thracian', 'artemis', 'and', 'also', 'because', 'i', 'wanted', 'to', 'see', 'in', 'what', 'manner', 'they', 'would', 'celebrate', 'the', 'festival', 'which', 'was', 'a', 'new', 'thing', 'i', 'was', 'delighted', 'with', 'the', 'procession', 'of', 'the', 'inhabitants', 'but', 'that', 'of', 'the', 'thracians', 'was', 'equally', 'if', 'not', 'more', 'beautiful', 'when', 'we', 'had', 'finished', 'our', 'prayers', 'and', 'viewed', 'the', 'spectacle', 'we', 'turned', 'in', 'the', 'direction', 'of', 'the', 'city', 'and', 'at', 'that', 'instant', 'polemarchus', 'the', 'son', 'of', 'cephalus', 'chanced', 'to', 'catch', 'sight', 'of', 'us', 'from', 'a', 'distance', 'as', 'we', 'were', 'starting', 'on', 'our', 'way', 'home', 'and', 'told', 'his', 'servant', 'to', 'run', 'and', 'bid', 'us', 'wait', 'for', 'him', 'the', 'servant', 'took', 'hold', 'of', 'me', 'by', 'the', 'cloak', 'behind', 'and', 'said', 'polemarchus', 'desires', 'you', 'to', 'wait', 'i', 'turned', 'round', 'and', 'asked', 'him', 'where', 'his', 'master', 'was', 'there', 'he', 'is', 'said', 'the', 'youth', 'coming', 'after', 'you', 'if', 'you', 'will', 'only', 'wait', 'certainly', 'we', 'will', 'said', 'glaucon', 'and', 'in', 'a', 'few', 'minutes', 'polemarchus', 'appeared', 'and', 'with', 'him', 'adeimantus', 'glaucons', 'brother', 'niceratus', 'the', 'son', 'of', 'nicias', 'and', 'several', 'others', 'who', 'had', 'been', 'at', 'the', 'procession', 'polemarchus', 'said', 'to', 'me']\n",
      "Total Tokens: 118683\n",
      "Unique Tokens: 7409\n"
     ]
    }
   ],
   "source": [
    "tokens = clean_document(doc)\n",
    "print(tokens[:201])\n",
    "print('Total Tokens: {}'.format(len(tokens)))\n",
    "print('Unique Tokens: {}'.format( len(set(tokens))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have the whole text splitted into an array of token ,  like 118683 tokens , we need to split it into an array of 51 tokens each why 51 tokens?\n",
    "\n",
    "The first 50 tokens will be our input and the last will be our output....\n",
    "\n",
    "We can do this by iterating over the list of tokens from token 51 onwards and taking the prior 50 tokens as a sequence, then repeating this process to the end of the list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentences is 118632\n"
     ]
    }
   ],
   "source": [
    "length = 50 + 1\n",
    "sequences = list()\n",
    "#TODO:  but this is ineficient \n",
    "for i in range(length, len(tokens)):\n",
    "    sequence = tokens[i-length:i]\n",
    "    line = ' '.join(sequence)\n",
    "    sequences.append(line)\n",
    "print(\"total sentences is {}\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted',\n",
       " 'i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with',\n",
       " 'went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the',\n",
       " 'down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession',\n",
       " 'yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of',\n",
       " 'to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the',\n",
       " 'the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants',\n",
       " 'piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but',\n",
       " 'with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that',\n",
       " 'glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of',\n",
       " 'the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the',\n",
       " 'son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians',\n",
       " 'of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was',\n",
       " 'ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally',\n",
       " 'that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if',\n",
       " 'i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not',\n",
       " 'might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more',\n",
       " 'offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful',\n",
       " 'up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when',\n",
       " 'my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we',\n",
       " 'prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had',\n",
       " 'to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished',\n",
       " 'the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our',\n",
       " 'goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers',\n",
       " 'bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and',\n",
       " 'the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed',\n",
       " 'thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the',\n",
       " 'artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle',\n",
       " 'and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we',\n",
       " 'also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned',\n",
       " 'because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in',\n",
       " 'i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the',\n",
       " 'wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction',\n",
       " 'to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of',\n",
       " 'see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the',\n",
       " 'in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city',\n",
       " 'what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and',\n",
       " 'manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at',\n",
       " 'they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that',\n",
       " 'would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant',\n",
       " 'celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus',\n",
       " 'the festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the',\n",
       " 'festival which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son',\n",
       " 'which was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son of',\n",
       " 'was a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son of cephalus',\n",
       " 'a new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son of cephalus chanced',\n",
       " 'new thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son of cephalus chanced to',\n",
       " 'thing i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son of cephalus chanced to catch',\n",
       " 'i was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son of cephalus chanced to catch sight',\n",
       " 'was delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son of cephalus chanced to catch sight of',\n",
       " 'delighted with the procession of the inhabitants but that of the thracians was equally if not more beautiful when we had finished our prayers and viewed the spectacle we turned in the direction of the city and at that instant polemarchus the son of cephalus chanced to catch sight of us']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let save everything to a file for later use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_document(lines, path):\n",
    "    \"\"\"\n",
    "    save the document to the given path\n",
    "    \"\"\"\n",
    "    data = '\\n'.join(lines)\n",
    "    with open(path , 'w') as file :\n",
    "        file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_document(sequences, 'data/republic_sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118632"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let reload our input data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = load_document('data/republic_sentences.txt')\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted',\n",
       " 'i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with',\n",
       " 'went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the',\n",
       " 'down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession',\n",
       " 'yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Preparing the text for the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our sentences , 118632 differents sentences... w\n",
    "\n",
    "we can now move to the preparation of our dataset for Machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are predicting the next word in a sentence , so our X is a sentence , and Y is the same sentence sifted by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the line above is x , our Y will be...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    line = line.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming sentences into list of tokens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for line in lines:\n",
    "    sentences.append(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.array(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how X looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus',\n",
       "       'with', 'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i',\n",
       "       'might', 'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess',\n",
       "       'bendis', 'the', 'thracian', 'artemis', 'and', 'also', 'because',\n",
       "       'i', 'wanted', 'to', 'see', 'in', 'what', 'manner', 'they',\n",
       "       'would', 'celebrate', 'the', 'festival', 'which', 'was', 'a',\n",
       "       'new', 'thing', 'i', 'was'], dtype='<U19')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Y looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus', 'with',\n",
       "       'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i', 'might',\n",
       "       'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess', 'bendis',\n",
       "       'the', 'thracian', 'artemis', 'and', 'also', 'because', 'i',\n",
       "       'wanted', 'to', 'see', 'in', 'what', 'manner', 'they', 'would',\n",
       "       'celebrate', 'the', 'festival', 'which', 'was', 'a', 'new',\n",
       "       'thing', 'i', 'was', 'delighted'], dtype='<U19')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , Y = sentences[:, :-1], sentences[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus',\n",
       "       'with', 'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i',\n",
       "       'might', 'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess',\n",
       "       'bendis', 'the', 'thracian', 'artemis', 'and', 'also', 'because',\n",
       "       'i', 'wanted', 'to', 'see', 'in', 'what', 'manner', 'they',\n",
       "       'would', 'celebrate', 'the', 'festival', 'which', 'was', 'a',\n",
       "       'new', 'thing', 'i', 'was'], dtype='<U19')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot encoding the token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our vocabulary we can replace each word in a sentence denoting his possition in our dictionary.\n",
    "based on that possition we can convert hours number into one hoted vector.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7409"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vocabulary has 7409 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word to an number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_number = {}\n",
    "for x in range(len(vocab)):\n",
    "    word_to_number[vocab[x]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_word = {}\n",
    "for word, number in word_to_number.items():\n",
    "    number_to_word[number] = word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert array of token to array of integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_number = np.vectorize(word_to_number.__getitem__)(X)\n",
    "Y_number = np.vectorize(word_to_number.__getitem__)(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the arrays are equals after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(X, np.vectorize(number_to_word.__getitem__)(X_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(Y, np.vectorize(number_to_word.__getitem__)(Y_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the variables check here for a [numpy solution](https://stackoverflow.com/a/36960495/4683950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 7406, 7407, 7408])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(X_number.max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def all_index(idx, axis):\n",
    "    \"\"\"\n",
    "    helper function for indexing\n",
    "    \"\"\"\n",
    "    grid = np.ogrid[tuple(map(slice, idx.shape))]\n",
    "    grid.insert(axis, idx)\n",
    "    return tuple(grid)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_initialization(a):\n",
    "    ncols = a.max()+1\n",
    "    out = np.zeros(a.shape + (ncols,), dtype=int)\n",
    "    out[all_index(a, axis=2)] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = one_hot_initialization(X_number)\n",
    "Y = one_hot_initialization(Y_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7409)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7409)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118632, 50, 7409)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118632, 50, 7409)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1951, 1951, 1395, 6504, 4319, 2905, 2986, 1158, 4285, 5633, 2986,\n",
       "       3028, 6859, 1352, 7317, 1951, 3791, 1954, 5836, 1502, 3295, 2905,\n",
       "       2986, 7392, 1583, 2986, 7205, 2680,  399, 5632, 1768, 1951, 4453,\n",
       "       2905, 5039, 7034, 5087, 5419,  866,  588, 3189, 2986, 5288, 5441,\n",
       "       1179, 5180, 4893, 2424, 1951, 1179])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(np.argmax(X[0], axis=1), X_number[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(X[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_word(array, number_to_word=number_to_word):\n",
    "    \"\"\"\n",
    "    convert a one hotte encoded array to word.\n",
    "    \"\"\"\n",
    "    x = np.argmax(array, axis=1)\n",
    "    return np.vectorize(number_to_word.__getitem__)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus',\n",
       "       'with', 'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i',\n",
       "       'might', 'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess',\n",
       "       'bendis', 'the', 'thracian', 'artemis', 'and', 'also', 'because',\n",
       "       'i', 'wanted', 'to', 'see', 'in', 'what', 'manner', 'they',\n",
       "       'would', 'celebrate', 'the', 'festival', 'which', 'was', 'a',\n",
       "       'new', 'thing', 'i', 'was'], dtype='<U9')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_to_word(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus', 'with',\n",
       "       'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i', 'might',\n",
       "       'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess', 'bendis',\n",
       "       'the', 'thracian', 'artemis', 'and', 'also', 'because', 'i',\n",
       "       'wanted', 'to', 'see', 'in', 'what', 'manner', 'they', 'would',\n",
       "       'celebrate', 'the', 'festival', 'which', 'was', 'a', 'new',\n",
       "       'thing', 'i', 'was', 'delighted'], dtype='<U9')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_to_word(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following part we will try to implement the network from scratch ans see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load scripts/functions.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x, derivate=False):\n",
    "    \"\"\"\n",
    "    Compute the element wise sigmoid for the array x\n",
    "    Args:\n",
    "        x ([type]): [description]\n",
    "        derivate (bool, optional): [description]. Defaults to False.\n",
    "    \"\"\"\n",
    "    x = x + 1e-12  # why are we doing this?\n",
    "    f = 1 / (1 + np.exp(x))\n",
    "    if derivate:\n",
    "        f = f * (1 - f)\n",
    "    else:\n",
    "        return f\n",
    "\n",
    "\n",
    "def tanh(x, derivate=False):\n",
    "    \"\"\"\n",
    "    Compute tanh function\n",
    "\n",
    "    Args:\n",
    "        x ([type]): [description]\n",
    "        derivate (bool, optional): [description]. Defaults to False.\n",
    "    \"\"\"\n",
    "    x = x + 1e-12\n",
    "\n",
    "    f = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "    if derivate:\n",
    "        return 1 - f**2\n",
    "    else:\n",
    "        return f\n",
    "\n",
    "\n",
    "def softmax(x, derivate=False):\n",
    "    \"\"\"\n",
    "    Compute softmax derivate of x\n",
    "\n",
    "    Args:\n",
    "        f ([type]): [description]\n",
    "        derivate (bool, optional): [description]. Defaults to False.\n",
    "    \"\"\"\n",
    "    x = x + 1e-12\n",
    "\n",
    "    f = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    if derivate:\n",
    "        pass\n",
    "    else:\n",
    "        return f\n",
    "\n",
    "\n",
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions.\n",
    "    Input: predictions (N, k)\n",
    "           targets (N, k)\n",
    "    Returns: scalar\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -np.mean(targets * np.log(predictions + 1e-9))\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def log_loss(y_predicted, y, derivate=False):\n",
    "    \"\"\"\n",
    "    Compute the log loss between the predicted output and the real output\n",
    "    Args:\n",
    "        y_predicted ([type]): [description]\n",
    "        y ([type]): [description]\n",
    "        derivate (bool, optional): [description]. Defaults to False.\n",
    "    \"\"\"\n",
    "    f = - y * np.log(y_predicted)\n",
    "\n",
    "    if derivate:\n",
    "        return - y / y_predicted\n",
    "    else:\n",
    "        return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load scripts/rnn.py\n",
    "import sys\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class RNNumpy:\n",
    "    def __init__(self, hidden_size, vocab_size, bptt_truncate=4):\n",
    "        \"\"\"\n",
    "        function help us to return  initialize the neural networks parameters\n",
    "        for text prediction the the number of input and\n",
    "        the number of output is equals to the vocabulary size, as well\n",
    "\n",
    "        Args:\n",
    "            hidden_size ([type]): [description]\n",
    "            vocab_size ([type]): [description]\n",
    "        \"\"\"\n",
    "        num_inputs = num_outputs = vocab_size\n",
    "\n",
    "        def normal(shape):\n",
    "            \"\"\"\n",
    "            Generate normal distribution but a lot can be done here\n",
    "\n",
    "            Args:\n",
    "                shape ([type]): [description]\n",
    "\n",
    "            Returns:\n",
    "                [type]: [description]\n",
    "            \"\"\"\n",
    "            return np.random.normal(scale=0.01, size=shape)\n",
    "\n",
    "        self.U = normal((hidden_size, num_inputs))\n",
    "        self.W = normal((hidden_size, hidden_size))\n",
    "        # Output layer parameters\n",
    "        self.V = normal((num_outputs, hidden_size))\n",
    "        self.b_hidden = np.zeros((hidden_size, 1))\n",
    "        self.b_out = np.zeros((vocab_size, 1))\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # TODO: I don't know the meaning of this yet but it will be clear soon\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        X denoting one training sample or a sentence\n",
    "\n",
    "        Args:\n",
    "            x ([type]): [description]\n",
    "        \"\"\"\n",
    "        T = len(x)\n",
    "        # we are saving all s in an numpy array\n",
    "        s = np.zeros((T, self.hidden_size))\n",
    "        s[-1] = np.zeros(self.hidden_size)  # we initialize it with zeros\n",
    "        o = np.zeros((T, self.vocab_size))\n",
    "        for t in np.arange(T):\n",
    "            s[t] = tanh(np.dot(self.U, x[t]) + self.W.dot(s[t - 1]))\n",
    "            o[t] = softmax(self.V.dot(s[t]))\n",
    "        return o, s\n",
    "\n",
    "    def predict(self, x):\n",
    "        o, s = self.forward(x)\n",
    "        return np.argmax(o, axis=1)\n",
    "\n",
    "    def calculate_loss(self, x, y):\n",
    "        \"\"\"\n",
    "        this will calculate the loss for one training example\n",
    "        we calculate the loss of y_1, y2,y3     and  be find the mean of it\n",
    "        TODO : is this the right approach?\n",
    "        \"\"\"\n",
    "        y_predicted, _ = self.forward(x)\n",
    "        log_loss = y * np.log(y_predicted)\n",
    "        return -np.mean(np.sum(log_loss, axis=1))\n",
    "\n",
    "    def calculate_total_loss(self, X, Y):\n",
    "        loss = 0.0\n",
    "        for i in range(len(Y)):\n",
    "            loss += self.calculate_loss(X[i], Y[i])\n",
    "        return loss / float(len(Y))\n",
    "    \n",
    "    def back_propagation_trough_time(self, x, y):\n",
    "        T = len(y)\n",
    "        o, s = self.forward(x)\n",
    "        dl_dU = np.zeros(self.U.shape)\n",
    "        dl_dV = np.zeros(self.V.shape)\n",
    "        dl_dW = np.zeros(self.W.shape)\n",
    "        # TODO: should implement o-Y\n",
    "        # seems to understand this but , I can improve it and make it readble o_t - y_t\n",
    "        delta_o = o[-1] - y[-1]\n",
    "        for t in np.arange(T):\n",
    "            dl_dV += np.outer(delta_o, s[t])\n",
    "            delta_t = self.V.T.dot(delta_o) * (1 - (np.power(s[t], 2)))\n",
    "\n",
    "            # TODO this part is not well understood, will improve it\n",
    "            for bptt_step in np.arange(\n",
    "                    max(0, t - self.bptt_truncate), t + 1)[::-1]:\n",
    "                dl_dW += np.outer(delta_t, s[bptt_step - 1])\n",
    "                dl_dU += np.outer(delta_t, x[t])\n",
    "                delta_t = self.W.T.dot(delta_t) * \\\n",
    "                    (1 - (np.power(s[bptt_step - 1], 2)))\n",
    "        return dl_dV, dl_dU, dl_dW\n",
    "\n",
    "    def numpy_sgd_step(self, x, y, learning_rate):\n",
    "        dL_dV, dL_dU, dL_dW = self.back_propagation_trough_time(x, y)\n",
    "        self.U -= learning_rate * dL_dU\n",
    "        self.V -= learning_rate * dL_dV\n",
    "        self.W -= learning_rate * dL_dW\n",
    "\n",
    "\n",
    "def train_with_sgd(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        learning_rate=0.005,\n",
    "        nepoch=100,\n",
    "        evaluate_loss_after=5):\n",
    "    \"\"\"\n",
    "    Train with sgd\n",
    "\n",
    "    Args:\n",
    "        model ([type]): [description]\n",
    "        x_train ([type]): [description]\n",
    "        y_train ([type]): [description]\n",
    "        learning_rate (float, optional): [description]. Defaults to 0.005.\n",
    "        nepoch (int, optional): [description]. Defaults to 100.\n",
    "        evaluate_loss_after (int, optional): [description]. Defaults to 5.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    num_examples_seen = 0\n",
    "    for epoch in range(nepoch):\n",
    "        if (epoch % evaluate_loss_after == 0):\n",
    "            loss = model.calculate_total_loss(x_train, y_train)\n",
    "            losses.append((epoch, num_examples_seen, loss))\n",
    "            time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print('{} loss after number of example seen = {} epoch = {}: {}'.format(time, num_examples_seen, epoch, loss))\n",
    "            \n",
    "            # setting the learning rate if it's increasing\n",
    "            if(len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                learning_rate = learning_rate * 0.5\n",
    "                print(f\"setting learning rate to {learning_rate}\")\n",
    "            sys.stdout.flush()\n",
    "        for i in range(len(y_train)):\n",
    "            model.numpy_sgd_step(x_train[i], y_train[i], learning_rate)\n",
    "            num_examples_seen += 1\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNNumpy(50, vocab_size=len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.910437361288848"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.calculate_loss(X[0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00013481, 0.00013504, 0.00013507, ..., 0.00013507, 0.00013501,\n",
       "       0.00013505])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_o[-1] - Y[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [p[0] for p in losses]\n",
    "y = [p[2] for p in losses]\n",
    "plt.plot(x, y)\n",
    "plt.title('loss of each epoch')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-13 21:14:29 loss after number of example seen = 0 epoch = 0: 8.910471836450384\n",
      "2020-04-13 21:16:56 loss after number of example seen = 400 epoch = 1: 8.909616987357108\n",
      "setting learning rate to 0.0025\n",
      "2020-04-13 21:19:15 loss after number of example seen = 800 epoch = 2: 8.905731341089929\n",
      "setting learning rate to 0.00125\n",
      "2020-04-13 21:21:29 loss after number of example seen = 1200 epoch = 3: 8.862861658845667\n",
      "setting learning rate to 0.000625\n",
      "2020-04-13 21:23:57 loss after number of example seen = 1600 epoch = 4: 6.239898255236687\n",
      "setting learning rate to 0.0003125\n",
      "2020-04-13 21:26:37 loss after number of example seen = 2000 epoch = 5: 6.011202003567245\n",
      "setting learning rate to 0.00015625\n",
      "2020-04-13 21:29:02 loss after number of example seen = 2400 epoch = 6: 5.83136170914172\n",
      "setting learning rate to 7.8125e-05\n",
      "2020-04-13 21:31:29 loss after number of example seen = 2800 epoch = 7: 5.767273609825919\n",
      "setting learning rate to 3.90625e-05\n",
      "2020-04-13 21:33:52 loss after number of example seen = 3200 epoch = 8: 5.745734429590274\n",
      "setting learning rate to 1.953125e-05\n",
      "2020-04-13 21:36:12 loss after number of example seen = 3600 epoch = 9: 5.729852803643923\n",
      "setting learning rate to 9.765625e-06\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-7bf758d1e58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_with_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_loss_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-190-410c0e39dab3>\u001b[0m in \u001b[0;36mtrain_with_sgd\u001b[0;34m(model, x_train, y_train, learning_rate, nepoch, evaluate_loss_after)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss of each epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "losses = train_with_sgd(rnn, X[:400], Y[:400], nepoch = 10, evaluate_loss_after = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2986, 2986, 2986,  399,  399,  399,  399,  399,  399,  399,  399,\n",
       "        399,  399,  399,  399,  399,  399,  399,  399,  399,  399,  399,\n",
       "        399,  399,  399,  399,  399,  399,  399,  399,  399,  399,  399,\n",
       "        399,  399,  399,  399,  399,  399,  399,  399,  399,  399,  399,\n",
       "        399,  399,  399,  399,  399,  399])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.predict(X[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['to', 'the', 'piraeus', 'with', 'glaucon', 'the', 'son', 'of',\n",
       "       'ariston', 'that', 'i', 'might', 'offer', 'up', 'my', 'prayers',\n",
       "       'to', 'the', 'goddess', 'bendis', 'the', 'thracian', 'artemis',\n",
       "       'and', 'also', 'because', 'i', 'wanted', 'to', 'see', 'in', 'what',\n",
       "       'manner', 'they', 'would', 'celebrate', 'the', 'festival', 'which',\n",
       "       'was', 'a', 'new', 'thing', 'i', 'was', 'delighted', 'with', 'the',\n",
       "       'procession', 'of'], dtype='<U10')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_to_word(Y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably', 'inevitably', 'inevitably',\n",
       "       'inevitably', 'inevitably'], dtype='<U10')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(number_to_word.__getitem__)(rnn.predict(X[1186]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-venv",
   "language": "python",
   "name": "deep-learning-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
