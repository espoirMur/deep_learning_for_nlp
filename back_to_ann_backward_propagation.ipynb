{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into implementing Backward propagation trought time, I decided to implement first backward propagation and then go to the step where we can implement it thought time.\n",
    "\n",
    "I will be using [this](https://blog.zhaytam.com/2018/08/15/implement-neural-network-backpropagation/) tutorial and the any other ressource I will find on the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    represent a layer of our neural network\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_input, neurons, weights=None, biais=None, activation=None):\n",
    "        \"\"\"\n",
    "        n_input : the numbers of input we pass to our network\n",
    "        neurons : the numbers of neurons in this layer\n",
    "        weights : the layer weights\n",
    "        biais   : the layer bias\n",
    "        \n",
    "        \"\"\"\n",
    "        self.weights = weights if weights else np.random.rand(n_input, neurons)\n",
    "        self.biais = biais if biais else np.random.rand(neurons)\n",
    "        self.activation = activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1 = Layer(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_1.weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83244264, 0.21233911, 0.18182497, 0.18340451])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_1.biais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the following activation function to the code :\n",
    "\n",
    "$\\sigma(X*W +B)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(self, x):\n",
    "    z = np.dot(x, self.weights) + self.biais\n",
    "    self.last_activation = self._apply_activation(z)\n",
    "    return self.last_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer.activate = activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_activation(self, normal):\n",
    "    \"\"\"\n",
    "    apply the activation function to the value pass in parameter\n",
    "    \"\"\"\n",
    "    if self.activation is None:\n",
    "        return normal\n",
    "    elif self.activation == 'tanh':\n",
    "        return np.tanh(normal)\n",
    "    elif self.activation == 'sigmoid':\n",
    "        return 1 / (1 + np.exp(normal))\n",
    "    ### what happen to relu?\n",
    "    return normal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer._apply_activation = _apply_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.32236508, 3.59926019, 1.09173962, 5.42414484])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_1.activate(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add our layers to our network and build it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    represent a neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        \"\"\"\n",
    "        add a layer to the network\n",
    "        layer : the layer to add to the network\n",
    "        \"\"\"\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def feed_foward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.activate(X)\n",
    "        return X\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict a class or class for multi ouput\n",
    "        \"\"\"\n",
    "        \n",
    "        outputs = self.feed_foward(X)\n",
    "        \n",
    "        if outputs.ndim == 1:\n",
    "            return np.argmax(outputs)\n",
    "        return np.argmax(outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_network = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_network.add_layer(Layer(2, 3, activation='tanh'))\n",
    "the_network.add_layer(Layer(3, 3, activation='sigmoid'))\n",
    "the_network.add_layer(Layer(3, 2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try to see how our network predict a binary operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_network.predict(np.array([[0, 0], [0, 1], [1, 0], [1, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_1.weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.48992243, 3.38692108, 0.90991465, 5.24074033]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([[1, 2, 3]]), hidden_layer_1.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase and Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let define a function that calculated sigmoid derivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_activation_derivative(self, r):\n",
    "    \"\"\"\n",
    "    Applies the derivative of the activation function (if any).\n",
    "    :param r: The normal value.\n",
    "    :return: The \"derived\" value.\n",
    "    \"\"\"\n",
    "\n",
    "    # We use 'r' directly here because its already activated, the only values that\n",
    "    # are used in this function are the last activations that were saved.\n",
    "\n",
    "    if self.activation is None:\n",
    "        return r\n",
    "\n",
    "    if self.activation == 'tanh':\n",
    "        return 1 - r ** 2\n",
    "\n",
    "    if self.activation == 'sigmoid':\n",
    "        return r * (1 - r)\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer.apply_activation_derivative = apply_activation_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation comes from this book on chapter 2 http://neuralnetworksanddeeplearning.com/chap2.html, for the intution and the algorithms calculation but the implementation comes from the same tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(self, X, y, learning_rate):\n",
    "    \"\"\"\n",
    "    Performs the backward propagation algorithm and updates the layers weights.\n",
    "    :param X: The input values.\n",
    "    :param y: The target values.\n",
    "    :param float learning_rate: The learning rate (between 0 and 1).\n",
    "    \"\"\"\n",
    "    output = self.feed_foward(X)\n",
    "    for i in reversed(range(len(self.layers))):\n",
    "        layer = self.layers[i]\n",
    "        if layer == self.layers[-1]: # if we are at the output\n",
    "            error = y - output\n",
    "            layer.delta = error * layer.apply_activation_derivative(output)\n",
    "        else :\n",
    "            next_layer =  self.layers[i+1] # layer i+1\n",
    "            layer.error = np.dot(next_layer.weights, next_layer.delta)\n",
    "            layer.delta = layer.error * layer.apply_activation_derivative(layer.last_activation)\n",
    "    for i, layer in enumerate(self.layers):\n",
    "        # we use X is we are at the first layer\n",
    "        input_to_use = np.atleast_2d(X if i == 0 else self.layers[i - 1].last_activation) # Z\n",
    "        layer.weights += layer.delta * input_to_use.T * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetwork.back_propagate = back_propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, X, y, learning_rate, max_epochs):\n",
    "    \"\"\"\n",
    "    Trains the neural network using backpropagation.\n",
    "    :param X: The input values.\n",
    "    :param y: The target values.\n",
    "    :param float learning_rate: The learning rate (between 0 and 1).\n",
    "    :param int max_epochs: The maximum number of epochs (cycles).\n",
    "    :return: The list of calculated MSE errors.\n",
    "    \"\"\"\n",
    "\n",
    "    mses = []\n",
    "\n",
    "    for i in range(max_epochs):\n",
    "        for j in range(len(X)):\n",
    "            self.back_propagate(X[j], y[j], learning_rate)\n",
    "        if i % 10 == 0:\n",
    "            mse = np.mean(np.square(y - self.feed_foward(X)))\n",
    "            mses.append(mse)\n",
    "            print('Epoch: #%s, MSE: %f' % (i, float(mse)))\n",
    "\n",
    "    return mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy between the predicted labels and true labels.\n",
    "    :param y_pred: The predicted labels.\n",
    "    :param y_true: The true labels.\n",
    "    :return: The calculated accuracy.\n",
    "    \"\"\"\n",
    "    return (y_pred == y_true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetwork.train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetwork.accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_network = NeuralNetwork()\n",
    "my_network.add_layer(Layer(2, 3, activation='tanh'))\n",
    "my_network.add_layer(Layer(3, 3, activation='sigmoid'))\n",
    "my_network.add_layer(Layer(3, 2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [0], [0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: #0, MSE: 0.221156\n",
      "Epoch: #10, MSE: 0.221143\n",
      "Epoch: #20, MSE: 0.221131\n",
      "Epoch: #30, MSE: 0.221119\n",
      "Epoch: #40, MSE: 0.221107\n",
      "Epoch: #50, MSE: 0.221095\n",
      "Epoch: #60, MSE: 0.221084\n",
      "Epoch: #70, MSE: 0.221073\n",
      "Epoch: #80, MSE: 0.221062\n",
      "Epoch: #90, MSE: 0.221052\n",
      "Epoch: #100, MSE: 0.221041\n",
      "Epoch: #110, MSE: 0.221031\n",
      "Epoch: #120, MSE: 0.221021\n",
      "Epoch: #130, MSE: 0.221011\n",
      "Epoch: #140, MSE: 0.221002\n",
      "Epoch: #150, MSE: 0.220992\n",
      "Epoch: #160, MSE: 0.220983\n",
      "Epoch: #170, MSE: 0.220974\n",
      "Epoch: #180, MSE: 0.220965\n",
      "Epoch: #190, MSE: 0.220957\n",
      "Epoch: #200, MSE: 0.220948\n",
      "Epoch: #210, MSE: 0.220940\n",
      "Epoch: #220, MSE: 0.220931\n",
      "Epoch: #230, MSE: 0.220923\n",
      "Epoch: #240, MSE: 0.220915\n",
      "Epoch: #250, MSE: 0.220907\n",
      "Epoch: #260, MSE: 0.220900\n",
      "Epoch: #270, MSE: 0.220892\n",
      "Epoch: #280, MSE: 0.220885\n",
      "Epoch: #290, MSE: 0.220877\n",
      "Epoch: #300, MSE: 0.220870\n",
      "Epoch: #310, MSE: 0.220863\n",
      "Epoch: #320, MSE: 0.220856\n",
      "Epoch: #330, MSE: 0.220849\n",
      "Epoch: #340, MSE: 0.220843\n",
      "Epoch: #350, MSE: 0.220836\n",
      "Epoch: #360, MSE: 0.220830\n",
      "Epoch: #370, MSE: 0.220823\n",
      "Epoch: #380, MSE: 0.220817\n",
      "Epoch: #390, MSE: 0.220811\n",
      "Epoch: #400, MSE: 0.220805\n",
      "Epoch: #410, MSE: 0.220799\n",
      "Epoch: #420, MSE: 0.220793\n",
      "Epoch: #430, MSE: 0.220787\n",
      "Epoch: #440, MSE: 0.220781\n",
      "Epoch: #450, MSE: 0.220775\n",
      "Epoch: #460, MSE: 0.220770\n",
      "Epoch: #470, MSE: 0.220764\n",
      "Epoch: #480, MSE: 0.220759\n",
      "Epoch: #490, MSE: 0.220754\n",
      "Epoch: #500, MSE: 0.220748\n",
      "Epoch: #510, MSE: 0.220743\n",
      "Epoch: #520, MSE: 0.220738\n",
      "Epoch: #530, MSE: 0.220733\n",
      "Epoch: #540, MSE: 0.220728\n",
      "Epoch: #550, MSE: 0.220723\n",
      "Epoch: #560, MSE: 0.220718\n",
      "Epoch: #570, MSE: 0.220714\n",
      "Epoch: #580, MSE: 0.220709\n",
      "Epoch: #590, MSE: 0.220704\n",
      "Epoch: #600, MSE: 0.220700\n",
      "Epoch: #610, MSE: 0.220695\n",
      "Epoch: #620, MSE: 0.220691\n",
      "Epoch: #630, MSE: 0.220686\n",
      "Epoch: #640, MSE: 0.220682\n",
      "Epoch: #650, MSE: 0.220678\n",
      "Epoch: #660, MSE: 0.220673\n",
      "Epoch: #670, MSE: 0.220669\n",
      "Epoch: #680, MSE: 0.220665\n",
      "Epoch: #690, MSE: 0.220661\n",
      "Epoch: #700, MSE: 0.220657\n",
      "Epoch: #710, MSE: 0.220653\n",
      "Epoch: #720, MSE: 0.220649\n",
      "Epoch: #730, MSE: 0.220645\n",
      "Epoch: #740, MSE: 0.220641\n",
      "Epoch: #750, MSE: 0.220638\n",
      "Epoch: #760, MSE: 0.220634\n",
      "Epoch: #770, MSE: 0.220630\n",
      "Epoch: #780, MSE: 0.220626\n",
      "Epoch: #790, MSE: 0.220623\n",
      "Epoch: #800, MSE: 0.220619\n",
      "Epoch: #810, MSE: 0.220616\n",
      "Epoch: #820, MSE: 0.220612\n",
      "Epoch: #830, MSE: 0.220609\n",
      "Epoch: #840, MSE: 0.220605\n",
      "Epoch: #850, MSE: 0.220602\n",
      "Epoch: #860, MSE: 0.220599\n",
      "Epoch: #870, MSE: 0.220596\n",
      "Epoch: #880, MSE: 0.220592\n",
      "Epoch: #890, MSE: 0.220589\n",
      "Epoch: #900, MSE: 0.220586\n",
      "Epoch: #910, MSE: 0.220583\n",
      "Epoch: #920, MSE: 0.220580\n",
      "Epoch: #930, MSE: 0.220577\n",
      "Epoch: #940, MSE: 0.220574\n",
      "Epoch: #950, MSE: 0.220571\n",
      "Epoch: #960, MSE: 0.220568\n",
      "Epoch: #970, MSE: 0.220565\n",
      "Epoch: #980, MSE: 0.220562\n",
      "Epoch: #990, MSE: 0.220559\n",
      "Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "errors = my_network.train(X, y, 0.5, 1000)\n",
    "accuracy = my_network.accuracy(my_network.predict(X), y.flatten())*100\n",
    "print('Accuracy: %.2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot changes in mse\n",
    "plt.plot(errors)\n",
    "plt.title('Changes in MSE')\n",
    "plt.xlabel('Epoch (every 10th)')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F*********k , \n",
    "it's increseaing instead of descresasing, let  me take a break and come back to this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's decreasing but not very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
